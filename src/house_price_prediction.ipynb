{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note : This project is very similar to the handwritten digits recognition notebook.\n",
    "# It is used to compare the performance of models with different hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networks implemented:\n",
    "# (i) MLP with single input layout, single output layer.\n",
    "# (ii) Add a single hidden layer to previous network\n",
    "# (iii) Add two hidden layers to previous network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (404, 13)\n",
      "y_train shape : (404,)\n",
      "x_test shape : (102, 13)\n",
      "y_test shape : (102,)\n",
      "\n",
      "x_train : [  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
      "y_train : 15.2\n"
     ]
    }
   ],
   "source": [
    "# Load the data using keras.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "print(\"x_train shape : {}\\ny_train shape : {}\\nx_test shape : {}\\ny_test shape : {}\\n\"\n",
    "      .format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))\n",
    "\n",
    "print(\"x_train : {}\".format(x_train[0]))\n",
    "print(\"y_train : {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data processing, to make values in range of 0..1 to make it easier for network to process values.\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(x_train)\n",
    "x_train = mms.transform(x_train)\n",
    "x_test = mms.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num input layes :  13\n"
     ]
    }
   ],
   "source": [
    "num_input_layers = len(x_train[0])\n",
    "print(\"num input layes : \", num_input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 10)                140       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151 (604.00 Byte)\n",
      "Trainable params: 151 (604.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 562.3536 - mae: 21.8750\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 552.4937 - mae: 21.6331\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 543.4545 - mae: 21.4105\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 534.4927 - mae: 21.1909\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 525.3895 - mae: 20.9628\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 516.1080 - mae: 20.7310\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 506.6156 - mae: 20.4921\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 496.9568 - mae: 20.2473\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 487.1744 - mae: 19.9928\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 477.3624 - mae: 19.7301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2838f6548d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network using keras.\n",
    "\n",
    "# Network one : Model with no hidden layers.\n",
    "network = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(10, input_dim = num_input_layers,activation='relu'),  # Input layer with num_input_layers neurons\n",
    "     tf.keras.layers.Dense(1, activation='linear')  # Output layer with 10 neurons \n",
    "])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "# Brief explanation of the network : \n",
    "# Sequential groups a linear stack of layers into a tk.keras.Model.\n",
    "# The network for input takes in number_of_inputs = num_input_layers.\n",
    "# Next, when we do tf.keras.layers.Dense, we mean:\n",
    "# We create a dense (fully connected) layer with 1 units and a relu activiation function.\n",
    "\n",
    "# Compile the network.\n",
    "network.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "network.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 498.1654 - mae: 20.2611\n",
      "MAE : 2026.1079788208008\n",
      "Loss : 498.1654052734375\n"
     ]
    }
   ],
   "source": [
    "# Evaluation performance of network.\n",
    "test_loss, test_acc = network.evaluate(x_test, y_test)\n",
    "print('MAE : {}'.format(test_acc * 100.0))\n",
    "print('Loss : {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                140       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               1100      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1341 (5.24 KB)\n",
      "Trainable params: 1341 (5.24 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 581.6588 - mae: 22.2921\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 557.9584 - mae: 21.7330\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 528.6711 - mae: 21.0254\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 490.3863 - mae: 20.0596\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 442.6201 - mae: 18.7710\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 387.2735 - mae: 17.1725\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 327.2603 - mae: 15.2888\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 267.3730 - mae: 13.3533\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 214.1725 - mae: 11.4592\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 170.4003 - mae: 9.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2838f72f310>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network using keras.\n",
    "\n",
    "# Network two : Model with one hidden layers.\n",
    "network = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(10, input_dim = num_input_layers,activation='relu'),  # Input layer with num_input_layers neurons\n",
    "     tf.keras.layers.Dense(100, activation='relu'),\n",
    "     tf.keras.layers.Dense(1, activation='linear')  # Output layer with 10 neurons \n",
    "])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "# Brief explanation of the network : \n",
    "# Sequential groups a linear stack of layers into a tk.keras.Model.\n",
    "# The network for input takes in number_of_inputs = num_input_layers.\n",
    "# Next, when we do tf.keras.layers.Dense, we mean:\n",
    "# We create a dense (fully connected) layer with 1 units and a relu activiation function.\n",
    "\n",
    "# Compile the network.\n",
    "network.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "network.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 162.3752 - mae: 9.9580\n",
      "MAE : 995.799446105957\n",
      "Loss : 162.3751678466797\n"
     ]
    }
   ],
   "source": [
    "# Evaluation performance of network.\n",
    "test_loss, test_acc = network.evaluate(x_test, y_test)\n",
    "print('MAE : {}'.format(test_acc * 100.0))\n",
    "print('Loss : {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 10)                140       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               1100      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 25)                2525      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3791 (14.81 KB)\n",
      "Trainable params: 3791 (14.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 562.5721 - mae: 21.8286\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 516.2535 - mae: 20.6886\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 457.7077 - mae: 19.1094\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 381.9009 - mae: 16.9296\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 296.1728 - mae: 14.1200\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 218.7312 - mae: 11.5549\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 167.1041 - mae: 9.9761\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 140.2185 - mae: 9.1392\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 123.4558 - mae: 8.5425\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 111.0824 - mae: 8.0948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2839064e450>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network using keras.\n",
    "\n",
    "# Network three : Model with 2 hidden layers.\n",
    "network = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(10, input_dim = num_input_layers,activation='relu'),  # Input layer with num_input_layers neurons\n",
    "     tf.keras.layers.Dense(100, activation='relu'),\n",
    "     tf.keras.layers.Dense(25, activation='relu'),\n",
    "     tf.keras.layers.Dense(1, activation='linear')  # Output layer with 10 neurons \n",
    "])\n",
    "\n",
    "network.summary()\n",
    "\n",
    "# Compile the network.\n",
    "network.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "network.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 109.0240 - mae: 7.8283\n",
      "MAE : 782.830810546875\n",
      "Loss : 109.02396392822266\n"
     ]
    }
   ],
   "source": [
    "# Evaluation performance of network.\n",
    "test_loss, test_acc = network.evaluate(x_test, y_test)\n",
    "print('MAE : {}'.format(test_acc * 100.0))\n",
    "print('Loss : {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "Model one   : MAE = 2026.1079, Loss : 498.165 \\\n",
    "Model two   : MAE = 995.7994, Loss : 162.375 \\\n",
    "Model three : Accuracy = 782.83, Loss : 109.023\n",
    "\n",
    "From the data above, we can see that adding more layers here got us higher accuracy (and) a lower loss function (as seen in comparison of metrics of Model two and Model three).\n",
    "However, as seen from the handwritten_digits_recognition notebook, this depends on a case by case basis, and is not the solution always (adding more layers was benefiical here, and in other projects led to poor results compared to fewer hiddne layers.)\n",
    " \n",
    "The first network (no hidden layer with the least number of trainable parameters) as expected performs the worst compared to the other two layers. This implies that having too few trainable parameters is not suitable, as overfitting is very likely to occur, and the network isn't complex enough in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
