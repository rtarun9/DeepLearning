{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple neural network to detect handwritten digits using the lenet 5 architecture.\n",
    "# The tensorflow library will be used to create the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (45000, 28, 28)\n",
      "y_train shape : (45000,)\n",
      "x_test shape : (10000, 28, 28)\n",
      "y_test shape : (10000,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train : 9\n"
     ]
    }
   ],
   "source": [
    "# Load the data using keras.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25)\n",
    "\n",
    "print(\"x_train shape : {}\\ny_train shape : {}\\nx_test shape : {}\\ny_test shape : {}\\n\"\n",
    "      .format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))\n",
    "\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"y_train : {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'zeros'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "2D convolution layer (e.g. spatial convolution over images).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input to produce a tensor of\n",
       "outputs. If `use_bias` is True,\n",
       "a bias vector is created and added to the outputs. Finally, if\n",
       "`activation` is not `None`, it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide the keyword argument `input_shape`\n",
       "(tuple of integers or `None`, does not include the sample axis),\n",
       "e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
       "in `data_format=\"channels_last\"`. You can use `None` when\n",
       "a dimension has variable size.\n",
       "\n",
       "Examples:\n",
       "\n",
       ">>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n",
       ">>> # size is 4.\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 26, 26, 2)\n",
       "\n",
       ">>> # With `dilation_rate` as 2.\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "...     2, 3,\n",
       "...     activation='relu',\n",
       "...     dilation_rate=2,\n",
       "...     input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 24, 24, 2)\n",
       "\n",
       ">>> # With `padding` as \"same\".\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 28, 28, 2)\n",
       "\n",
       ">>> # With extended batch shape [4, 7]:\n",
       ">>> input_shape = (4, 7, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 7, 26, 26, 2)\n",
       "\n",
       "\n",
       "Args:\n",
       "  filters: Integer, the dimensionality of the output space (i.e. the number\n",
       "    of output filters in the convolution).\n",
       "  kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
       "    and width of the 2D convolution window. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions.\n",
       "  strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
       "    the convolution along the height and width. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions. Specifying any stride\n",
       "    value != 1 is incompatible with specifying any `dilation_rate` value !=\n",
       "    1.\n",
       "  padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n",
       "    evenly to the left/right or up/down of the input. When `padding=\"same\"`\n",
       "    and `strides=1`, the output has the same size as the input.\n",
       "  data_format: A string, one of `channels_last` (default) or\n",
       "    `channels_first`.  The ordering of the dimensions in the inputs.\n",
       "    `channels_last` corresponds to inputs with shape `(batch_size, height,\n",
       "    width, channels)` while `channels_first` corresponds to inputs with\n",
       "    shape `(batch_size, channels, height, width)`. It defaults to the\n",
       "    `image_data_format` value found in your Keras config file at\n",
       "    `~/.keras/keras.json`. If you never set it, then it will be\n",
       "    `channels_last`. Note that the `channels_first` format is currently not\n",
       "    supported by TensorFlow on CPU.\n",
       "  dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
       "    dilation rate to use for dilated convolution. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions. Currently, specifying\n",
       "    any `dilation_rate` value != 1 is incompatible with specifying any\n",
       "    stride value != 1.\n",
       "  groups: A positive integer specifying the number of groups in which the\n",
       "    input is split along the channel axis. Each group is convolved\n",
       "    separately with `filters / groups` filters. The output is the\n",
       "    concatenation of all the `groups` results along the channel axis. Input\n",
       "    channels and `filters` must both be divisible by `groups`.\n",
       "  activation: Activation function to use. If you don't specify anything, no\n",
       "    activation is applied (see `keras.activations`).\n",
       "  use_bias: Boolean, whether the layer uses a bias vector.\n",
       "  kernel_initializer: Initializer for the `kernel` weights matrix (see\n",
       "    `keras.initializers`). Defaults to 'glorot_uniform'.\n",
       "  bias_initializer: Initializer for the bias vector (see\n",
       "    `keras.initializers`). Defaults to 'zeros'.\n",
       "  kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
       "    matrix (see `keras.regularizers`).\n",
       "  bias_regularizer: Regularizer function applied to the bias vector (see\n",
       "    `keras.regularizers`).\n",
       "  activity_regularizer: Regularizer function applied to the output of the\n",
       "    layer (its \"activation\") (see `keras.regularizers`).\n",
       "  kernel_constraint: Constraint function applied to the kernel matrix (see\n",
       "    `keras.constraints`).\n",
       "  bias_constraint: Constraint function applied to the bias vector (see\n",
       "    `keras.constraints`).\n",
       "\n",
       "Input shape:\n",
       "  4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n",
       "    `data_format='channels_first'`\n",
       "  or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n",
       "    `data_format='channels_last'`.\n",
       "\n",
       "Output shape:\n",
       "  4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n",
       "  `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n",
       "    (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n",
       "    and `cols` values might have changed due to padding.\n",
       "\n",
       "Returns:\n",
       "  A tensor of rank 4+ representing\n",
       "  `activation(conv2d(inputs, kernel) + bias)`.\n",
       "\n",
       "Raises:\n",
       "  ValueError: if `padding` is `\"causal\"`.\n",
       "  ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\tarun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages\\keras\\src\\layers\\convolutional\\conv2d.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     Conv2DTranspose"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               30840     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44426 (173.54 KB)\n",
      "Trainable params: 44426 (173.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the network using keras.\n",
    "# Linet 5 architecture : Input, Convolution, Maxpooling, convolution, maxpolling, Fully connected, fully connected, fullyconnected (output)\n",
    "# Layer 1> 6 filter of size 5x5\n",
    "# Layer 2> Maxpooling of size 2x2\n",
    "# Layer 3> Convolution (16), filter size 5x5\n",
    "# Layer 4> Maxpooling of size 2x2\n",
    "# Layer 5> Dense Full connected (120) nodes.\n",
    "# Layer 6> Same as before, with 84 nodes.\n",
    "# Layer 7> Final, 10 nodes in dense layer.\n",
    "\n",
    "linet_5_model = tf.keras.Sequential([\n",
    "     tf.keras.layers.Input(shape=(28,28,1)),  \n",
    "     tf.keras.layers.Conv2D(6, 5, activation='relu'),\n",
    "     tf.keras.layers.MaxPooling2D(2),\n",
    "     tf.keras.layers.Conv2D(16, 5, activation='relu'),\n",
    "     tf.keras.layers.MaxPooling2D(2),\n",
    "     tf.keras.layers.Flatten(),\n",
    "     tf.keras.layers.Dense(120, activation='relu'),\n",
    "     tf.keras.layers.Dense(84, activation='relu'),\n",
    "     tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "linet_5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mlinet_5_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (dataset iterations).\n",
       "\n",
       "Args:\n",
       "    x: Input data. It could be:\n",
       "      - A Numpy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "      - A TensorFlow tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "      - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "      - A `tf.data` dataset. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "      - A generator or `keras.utils.Sequence` returning `(inputs,\n",
       "        targets)` or `(inputs, targets, sample_weights)`.\n",
       "      - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
       "        callable that takes a single argument of type\n",
       "        `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
       "        `DatasetCreator` should be used when users prefer to specify the\n",
       "        per-replica batching and sharding logic for the `Dataset`.\n",
       "        See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
       "        information.\n",
       "      A more detailed description of unpacking behavior for iterator\n",
       "      types (Dataset, generator, Sequence) is given below. If these\n",
       "      include `sample_weights` as a third component, note that sample\n",
       "      weighting applies to the `weighted_metrics` argument but not the\n",
       "      `metrics` argument in `compile()`. If using\n",
       "      `tf.distribute.experimental.ParameterServerStrategy`, only\n",
       "      `DatasetCreator` type is supported for `x`.\n",
       "    y: Target data. Like the input data `x`,\n",
       "      it could be either Numpy array(s) or TensorFlow tensor(s).\n",
       "      It should be consistent with `x` (you cannot have Numpy inputs and\n",
       "      tensor targets, or inversely). If `x` is a dataset, generator,\n",
       "      or `keras.utils.Sequence` instance, `y` should\n",
       "      not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence`\n",
       "        instances (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided\n",
       "        (unless the `steps_per_epoch` flag is set to\n",
       "        something other than None).\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        'auto' becomes 1 for most cases, but 2 when used with\n",
       "        `ParameterServerStrategy`. Note that the progress bar is not\n",
       "        particularly useful when logged to a file, so verbose=2 is\n",
       "        recommended when not running interactively (eg, in a production\n",
       "        environment). Defaults to 'auto'.\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `tf.keras.callbacks`. Note\n",
       "        `tf.keras.callbacks.ProgbarLogger` and\n",
       "        `tf.keras.callbacks.History` callbacks are created automatically\n",
       "        and need not be passed into `model.fit`.\n",
       "        `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
       "        `verbose` argument to `model.fit`.\n",
       "        Callbacks with batch-level calls are currently unsupported with\n",
       "        `tf.distribute.experimental.ParameterServerStrategy`, and users\n",
       "        are advised to implement epoch-level calls instead with an\n",
       "        appropriate `steps_per_epoch` value.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This\n",
       "        argument is not supported when `x` is a dataset, generator or\n",
       "        `keras.utils.Sequence` instance.\n",
       "        If both `validation_data` and `validation_split` are provided,\n",
       "        `validation_data` will override `validation_split`.\n",
       "        `validation_split` is not yet supported with\n",
       "        `tf.distribute.experimental.ParameterServerStrategy`.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data. Thus, note the fact\n",
       "        that the validation loss of data provided using\n",
       "        `validation_split` or `validation_data` is not affected by\n",
       "        regularization layers like noise and dropout.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        `validation_data` could be:\n",
       "          - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
       "          - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
       "            arrays.\n",
       "          - A `tf.data.Dataset`.\n",
       "          - A Python generator or `keras.utils.Sequence` returning\n",
       "          `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
       "        `validation_data` is not yet supported with\n",
       "        `tf.distribute.experimental.ParameterServerStrategy`.\n",
       "    shuffle: Boolean (whether to shuffle the training data\n",
       "        before each epoch) or str (for 'batch'). This argument is\n",
       "        ignored when `x` is a generator or an object of tf.data.Dataset.\n",
       "        'batch' is a special option for dealing\n",
       "        with the limitations of HDF5 data; it shuffles in batch-sized\n",
       "        chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class. When `class_weight` is specified\n",
       "        and targets have a rank of 2 or greater, either `y` must be\n",
       "        one-hot encoded, or an explicit final dimension of `1` must\n",
       "        be included for sparse class labels.\n",
       "    sample_weight: Optional Numpy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        Numpy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample.\n",
       "        This argument is not supported when `x` is a dataset, generator,\n",
       "        or `keras.utils.Sequence` instance, instead provide the\n",
       "        sample_weights as the third element of `x`.\n",
       "        Note that sample weighting does not apply to metrics specified\n",
       "        via the `metrics` argument in `compile()`. To apply sample\n",
       "        weighting to your metrics, you can specify them via the\n",
       "        `weighted_metrics` in `compile()` instead.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        TensorFlow data tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If x is a\n",
       "        `tf.data` dataset, and 'steps_per_epoch'\n",
       "        is None, the epoch will run until the input dataset is\n",
       "        exhausted.  When passing an infinitely repeating dataset, you\n",
       "        must specify the `steps_per_epoch` argument. If\n",
       "        `steps_per_epoch=-1` the training will run indefinitely with an\n",
       "        infinitely repeating dataset.  This argument is not supported\n",
       "        with array inputs.\n",
       "        When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
       "          * `steps_per_epoch=None` is not supported.\n",
       "    validation_steps: Only relevant if `validation_data` is provided and\n",
       "        is a `tf.data` dataset. Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If 'validation_steps' is None,\n",
       "        validation will run until the `validation_data` dataset is\n",
       "        exhausted. In the case of an infinitely repeated dataset, it\n",
       "        will run into an infinite loop. If 'validation_steps' is\n",
       "        specified and only part of the dataset will be consumed, the\n",
       "        evaluation will start from the beginning of the dataset at each\n",
       "        epoch. This ensures that the same validation samples are used\n",
       "        every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in\n",
       "        the form of datasets, generators, or `keras.utils.Sequence`\n",
       "        instances (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided.\n",
       "      Integer or `collections.abc.Container` instance (e.g. list, tuple,\n",
       "      etc.).  If an integer, specifies how many training epochs to run\n",
       "      before a new validation run is performed, e.g. `validation_freq=2`\n",
       "      runs validation every 2 epochs. If a Container, specifies the\n",
       "      epochs on which to run validation, e.g.\n",
       "      `validation_freq=[1, 2, 10]` runs validation at the end of the\n",
       "      1st, 2nd, and 10th epochs.\n",
       "    max_queue_size: Integer. Used for generator or\n",
       "      `keras.utils.Sequence` input only. Maximum size for the generator\n",
       "      queue.  If unspecified, `max_queue_size` will default to 10.\n",
       "    workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
       "        only. Maximum number of processes to spin up\n",
       "        when using process-based threading. If unspecified, `workers`\n",
       "        will default to 1.\n",
       "    use_multiprocessing: Boolean. Used for generator or\n",
       "        `keras.utils.Sequence` input only. If `True`, use process-based\n",
       "        threading. If unspecified, `use_multiprocessing` will default to\n",
       "        `False`. Note that because this implementation relies on\n",
       "        multiprocessing, you should not pass non-picklable arguments to\n",
       "        the generator as they can't be passed easily to children\n",
       "        processes.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass a tf.data.Dataset, generator, or\n",
       "  tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
       "  yield not only features (x) but optionally targets (y) and sample\n",
       "  weights.  Keras requires that the output of such iterator-likes be\n",
       "  unambiguous. The iterator should return a tuple of length 1, 2, or 3,\n",
       "  where the optional second and third elements will be used for y and\n",
       "  sample_weight respectively. Any other type provided will be wrapped in\n",
       "  a length one tuple, effectively treating everything as 'x'. When\n",
       "  yielding dicts, they should still adhere to the top-level tuple\n",
       "  structure.\n",
       "  e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "  features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the namedtuple. The reason is\n",
       "  that it behaves like both an ordered datatype (tuple) and a mapping\n",
       "  datatype (dict). So given a namedtuple of the form:\n",
       "      `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "  it is ambiguous whether to reverse the order of the elements when\n",
       "  interpreting the value. Even worse is a tuple of the form:\n",
       "      `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "  where it is unclear if the tuple was intended to be unpacked into x,\n",
       "  y, and sample_weight or passed through as a single element to `x`. As\n",
       "  a result the data processing code will simply raise a ValueError if it\n",
       "  encounters a namedtuple. (Along with instructions to remedy the\n",
       "  issue.)\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\n",
       "Raises:\n",
       "    RuntimeError: 1. If the model was never compiled or,\n",
       "    2. If `model.fit` is  wrapped in `tf.function`.\n",
       "\n",
       "    ValueError: In case of mismatch between the provided input data\n",
       "        and what the model expects or when the input data is empty.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\tarun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages\\keras\\src\\engine\\training.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linet_5_model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 17s 11ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.0628 - val_accuracy: 0.9856\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 0.0453 - val_accuracy: 0.9896\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0393 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.0420 - val_accuracy: 0.9908\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.0414 - val_accuracy: 0.9905\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0525 - val_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0536 - val_accuracy: 0.9877\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0462 - val_accuracy: 0.9884\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.1056 - val_accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 0.0633 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15f10652290>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compile the network.\n",
    "linet_5_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "linet_5_model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0712 - accuracy: 0.9853\n",
      "Accuracy : 98.53000044822693\n",
      "Loss : 0.07122769951820374\n"
     ]
    }
   ],
   "source": [
    "# Evaluation performance of network.\n",
    "test_loss, test_acc = linet_5_model.evaluate(x_test, y_test)\n",
    "print('Accuracy : {}'.format(test_acc * 100.0))\n",
    "print('Loss : {}'.format(test_loss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
